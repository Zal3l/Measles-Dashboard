{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of weekly confirmed cases of Measles for all ages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import ipywidgets as wdg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# make figures larger\n",
    "plt.rcParams['figure.dpi'] = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load JSON files and store the raw data in jsondata\n",
    "jsondata={}\n",
    "#three files previously produced to represent the spread of measles per week in three UKHSA areas (london, East Midlands and East of England)\n",
    "def file_opener():\n",
    "    with open(\"East Midlands.json\", \"rt\") as INFILE:\n",
    "        jsondata['East Midlands']=json.load(INFILE)\n",
    "    with open(\"London.json\", \"rt\") as INFILE:\n",
    "        jsondata['London']=json.load(INFILE)\n",
    "    with open(\"East of England.json\", \"rt\") as INFILE:\n",
    "        jsondata['East of England']=json.load(INFILE) \n",
    "    return\n",
    "\n",
    "file_opener() #here to run the graphs for the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3423/2841698013.py:42: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df.fillna(0.0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "'''Wrangling data section'''\n",
    "\n",
    "\n",
    "def parse_date(datestring):\n",
    "    \"\"\" Convert a date string into a pandas datetime object \"\"\"\n",
    "    return pd.to_datetime(datestring, format=\"%Y-%m-%d\")                #Code taken from 2-Visualising_the_data\n",
    "\n",
    "def wrangle_data(rawdata):\n",
    "    \"\"\" Parameters: rawdata - data from json file or API call. Returns a dataframe.\n",
    "    Edit to include the code that wrangles the data, creates the dataframe and fills it in. \"\"\"\n",
    "    global df\n",
    "    data={}\n",
    "    for dataset in rawdata.values():\n",
    "        for entry in dataset:\n",
    "            date=entry['date']\n",
    "            geography=entry['geography']\n",
    "            value=entry['metric_value']\n",
    "            if date not in data:\n",
    "                data[date]={}\n",
    "            data[date][geography]=value\n",
    "    dates=list(data.keys())\n",
    "    dates.sort()\n",
    "    #creating and sorting a dictionary with the useful information from the data files (taken and adapted from 2-Visualising_the_data)\n",
    "    \n",
    "    startdate=parse_date(dates[0])\n",
    "    enddate=parse_date(dates[-1])\n",
    "    index=pd.date_range(startdate, enddate, freq='W-MON')\n",
    "    #converting dates to pandas type so can be used in Dataframe (taken and adapted from 2-Visualising_the_data)\n",
    "    #data provided about measles provided weekly on for date starting on monday\n",
    "\n",
    "    geographies=list(jsondata.keys()) #this is a list of my geographies. it is taken from the keys assigned in file_opener. It allows me to iterate for however many APIs I download (tested with 2 and 3)\n",
    "    \n",
    "    df=pd.DataFrame(index=index, columns=geographies)\n",
    "    #making empty dataframe\n",
    "\n",
    "    for date, entry in data.items():\n",
    "        pd_date=parse_date(date)\n",
    "        for column in geographies: \n",
    "            location=column               #code adapted so it's working with location\n",
    "            value= entry.get(location, 0.0)\n",
    "            df.loc[date, column]=value    #uses loc to assign value the date and value\n",
    "    df.fillna(0.0, inplace=True)\n",
    "    df.infer_objects(copy=False) #this was put in from the future warning\n",
    "    return\n",
    "    #code taken and adapted from 2-Visualising_the_data\n",
    "\n",
    "# putting the wrangling code into a function allows you to call it again after refreshing the data through \n",
    "# the API. You should call the function directly on the JSON data when the dashboard starts, by including \n",
    "# the call in this cell as below:\n",
    "wrangle_data(jsondata) # here to run the graphs for the first time on load up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Downloading the current data'''\n",
    "\n",
    "\n",
    "\n",
    "#APIwrapper implemented as a class that is called by function access_API. So that when the information is accessed,\n",
    "#it is immediately wrapped and via the access_API function it is immediately saved (overwrites)\n",
    "#the JSON file corresponding to each location\n",
    "\n",
    "#Code left unchanged, taken from 1- Accessing_UKHSA_Data\n",
    "class APIwrapper:\n",
    "    # class variables shared among all instances\n",
    "    _access_point=\"https://api.ukhsa-dashboard.data.gov.uk\"\n",
    "    _last_access=0.0 # time of last api access\n",
    "\n",
    "    def __init__(self, theme, sub_theme, topic, geography_type, geography, metric):\n",
    "        \"\"\" Init the APIwrapper object, constructing the endpoint from the structure\n",
    "        parameters \"\"\"\n",
    "        # build the path with all the required structure parameters. You do not need to edit this line,\n",
    "        # parameters will be replaced by the actual values when you instantiate an object of the class!\n",
    "        url_path=(f\"/themes/{theme}/sub_themes/{sub_theme}/topics/{topic}/geography_types/\" +\n",
    "                    f\"{geography_type}/geographies/{geography}/metrics/{metric}\")\n",
    "        # our starting API endpoint\n",
    "        self._start_url=APIwrapper._access_point+url_path\n",
    "        self._filters=None\n",
    "        self._page_size=-1\n",
    "        # will contain the number of items\n",
    "        self.count=None\n",
    "\n",
    "    def get_page(self, filters={}, page_size=5):\n",
    "        \"\"\" Access the API and download the next page of data. Sets the count\n",
    "        attribute to the total number of items available for this query. Changing\n",
    "        filters or page_size will cause get_page to restart from page 1. Rate\n",
    "        limited to three request per second. The page_size parameter sets the number\n",
    "        of data points in one response page (maximum 365); use the default value \n",
    "        for debugging your structure and filters. \"\"\"\n",
    "        # Check page size is within range\n",
    "        if page_size>365:\n",
    "            raise ValueError(\"Max supported page size is 365\")\n",
    "        # restart from first page if page or filters have changed\n",
    "        if filters!=self._filters or page_size!=self._page_size:\n",
    "            self._filters=filters\n",
    "            self._page_size=page_size\n",
    "            self._next_url=self._start_url\n",
    "        # signal the end of data condition\n",
    "        if self._next_url==None: \n",
    "            return [] # we already fetched the last page\n",
    "        # simple rate limiting to avoid bans\n",
    "        curr_time=time.time() # Unix time: number of seconds since the Epoch\n",
    "        deltat=curr_time-APIwrapper._last_access\n",
    "        if deltat<0.33: # max 3 requests/second\n",
    "            time.sleep(0.33-deltat)\n",
    "        APIwrapper._last_access=curr_time\n",
    "        # build parameter dictionary by removing all the None\n",
    "        # values from filters and adding page_size\n",
    "        parameters={x: y for x, y in filters.items() if y!=None}\n",
    "        parameters['page_size']=page_size\n",
    "        # the page parameter is already included in _next_url.\n",
    "        # This is the API access. Response is a dictionary with various keys.\n",
    "        # the .json() method decodes the response into Python object (dictionaries,\n",
    "        # lists; 'null' values are translated as None).\n",
    "        response = requests.get(self._next_url, params=parameters).json()\n",
    "        # update url so we'll fetch the next page\n",
    "        self._next_url=response['next']\n",
    "        self.count=response['count']\n",
    "        # data are in the nested 'results' list\n",
    "        return response['results'] \n",
    "\n",
    "    def get_all_pages(self, filters={}, page_size=365):\n",
    "        \"\"\" Access the API and download all available data pages of data. Sets the count\n",
    "        attribute to the total number of items available for this query. API access rate\n",
    "        limited to three request per second. The page_size parameter sets the number\n",
    "        of data points in one response page (maximum 365), and controls the trade-off\n",
    "        between time to load a page and number of pages; the default should work well \n",
    "        in most cases. The number of items returned should in any case be equal to \n",
    "        the count attribute. \"\"\"\n",
    "        data=[] # build up all data here\n",
    "        while True:\n",
    "            # use get_page to do the job, including the pacing\n",
    "            next_page=self.get_page(filters, page_size)\n",
    "            if next_page==[]:\n",
    "                break # we are done\n",
    "            data.extend(next_page)\n",
    "        return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def access_api():\n",
    "    \"\"\" Accesses the UKHSA API. Return data as a like-for-like replacement for the \"canned\" data loaded from the JSON file. \"\"\"\n",
    "                           #Fabrizio Code (from lectures)\n",
    "    structure={\"theme\": \"infectious_disease\", \n",
    "               \"sub_theme\": \"vaccine_preventable\",\n",
    "               \"topic\": \"Measles\",\n",
    "               \"geography_type\": \"UKHSA%20Region\",\n",
    "               \"metric\": \"measles_cases_casesByOnsetWeek\"}\n",
    "    #structure put in here for convenience, can be pulled out and changed to be a dictionary that can be changed at peoples whims, but requirement is only one graph.\n",
    "\n",
    "    #Taken from 1-Accessing_UKHSA_Data, adapted to change structure for geographical location instead of for different metrics\n",
    "    geographies=list(jsondata.keys()) #this is a list of my geographies. it is taken from the keys assigned in file_opener. It allows me to iterate for however many APIs I download (tested with 2 and 3)\n",
    "    for geography in geographies:\n",
    "        structure[\"geography\"]= geography\n",
    "        api=APIwrapper(**structure)\n",
    "        cases=api.get_all_pages(page_size=365)                     #pulling page_size 365 to pull all the data faster (not necessary, but just runs faster)\n",
    "        with open(structure[\"geography\"]+'.json', \"wt\") as OUTF:\n",
    "            json.dump(cases, OUTF)                                 #overwrites the JSON file with corresponding name when refreshing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#framework taken from original dashboard and adapted.\n",
    "\n",
    "\n",
    "def api_button_callback(button):\n",
    "    with output:\n",
    "        output.clear_output(wait=True)   #This resets my output so that when my graph refreshes, it doesn't just post a new one\n",
    "        print(\"Graph Refreshing\")        #Put in my output to allow for people to clearly see when the graph is refreshing. \n",
    "    try:\n",
    "        access_api()\n",
    "        file_opener()\n",
    "        df=wrangle_data(jsondata)  \n",
    "        refresh_graph()\n",
    "        apibutton.icon = \"check\"\n",
    "        #apibutton.disabled=True  -- got rid of this, but left in code. Wanted to be able to continuously refresh the graph if person wanted to.\n",
    "        with output:\n",
    "            print('Graphs refreshed')\n",
    "    except Exception as e:\n",
    "        with output:\n",
    "            print(\"Error:\",e)  # Error capturing\n",
    "\n",
    "#Taken from 3- Adding_interactive_controls. Code worked perfectly so left unchanged\n",
    "apibutton=wdg.Button(\n",
    "    description='Refresh data',\n",
    "    disabled=False,\n",
    "    button_style='', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Click to download current Public Health England data',\n",
    "    icon='download' # (FontAwesome names without the `fa-` prefix)\n",
    ")\n",
    "\n",
    "\n",
    "#Button is called next to graph, instead of at this box to allow easy access for users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph (Based on UK Government data published by the UK Health Security Agency) shows the number of weekly laboratory confirmed cases of measles, reported to UKHSA, by date of onset of rash (or symptoms), age group, and UKHSA Region from 1 October 2023 onwards.\n",
    "\n",
    "To interact with this graph you can search through 3 distinct UKHSA areas of the UK to view confirmed measles cases in each area, or click on any combination to show multiple graphs overlayed on each other. \n",
    "\n",
    "A refresh button is available, enabling you to update the data directly from the UK Health Security Agency website. If you are highlighting only one graph and refresh, then you will have to swap to another to show the refreshed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Graph plotting and analysis section'''\n",
    "\n",
    "\n",
    "\n",
    "def plot_graph(column):                #kept from original dashboard, input had to be a list for multiple plots \n",
    "    \"\"\" Our sample graph plotting function \"\"\"\n",
    "    df[list(column)].plot()\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Number of confirmed measles cases per day\")\n",
    "    plt.show() # important! update won't work properly without this\n",
    "\n",
    "# a sample widget\n",
    "column=wdg.SelectMultiple(            #Taken from 3- Adding_interactive_controls and adapted to use the columns of my dataframe as the options and values list\n",
    "    options=list(df.columns),\n",
    "    value=list(df.columns),\n",
    "    rows=len(df.columns),            #Rows = length of the number of columns. i.e in my case 3, but allows for easy access to update with more information. \n",
    "    description='Location',\n",
    "    disabled=False,\n",
    ")\n",
    "\n",
    "controls=wdg.HBox([column])\n",
    "\n",
    "\n",
    "def refresh_graph():\n",
    "    \"\"\" We change the value of the widget in order to force a redraw of the graph;\n",
    "    this is useful when the data have been updated. This is a bit of a gimmick; it\n",
    "    needs to be customised for one of your widgets. \"\"\"\n",
    "    current=column.value\n",
    "    if current==column.options[0]:\n",
    "        other=[column.options[1]]   #Adapted from refresh graph, had to list as a tuple/list\n",
    "    else:\n",
    "        other=[column.options[1]]\n",
    "    column.value=other # forces the redraw\n",
    "    column.value=current # now we can change it back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c7534947f8146b9811c65b983e8f587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Refresh data', icon='download', style=ButtonStyle(), tooltip='Click to download current Pu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dbf2e2cbaac46f991ab7e06cc8c6427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64db3345472a4152b70e2d53661bd5e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "SelectMultiple(description='Location', index=(0, 1, 2), options=('East Midlands', 'London', 'East of England')…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feacd2318adf41fe8fa5ed92d0e7f925",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "apibutton.on_click(api_button_callback) #put here because button is called in this cell,\n",
    "output = wdg.Output()                   #this is here so that I can print information about the data being refreshed when the button is called\n",
    "graph=wdg.interactive_output(plot_graph, {'column': column})\n",
    "display(apibutton,output,column,graph)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
